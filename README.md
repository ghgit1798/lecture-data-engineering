프로그래머스 데이터 엔지니어링 강의 1주차를 수강하며 느낀점을 정리해보려고 합니다.

## ⭐ OT

OT의 주요 내용은 Data Engineer가 하는 일과 학습 시 유의점에 대한 내용이 주를 이루고 있었습니다. 특히 학습 시 중요한 점은 두 가지였습니다.

1. 21세기는 학습 능력이 핵심 ⭕ 
2. 하지만 당장 필요하지 않는 선행학습, 불안감을 위한 선행학습은 ❌

### 🔴 학습 시 숙지할 것

처음 학습 시 어려운 점을 맞닥뜨릴 시 3가지를 명심하자.

1. 고통스럽지만 시간을 투자해서 버티는 힘
    1. 최소한 3-6개월 Full-Time으로 버티면서 공부해보자
2. 내가 뭘 모르는 지 정의하고 찾아볼 것
    1. 내가 어디서 막혔는 지 구체적으로 질문할 수 있는가?
3. **잘하는 사람 보고 기죽지 않기**
    1. ⭐ 남하고 비교하지 않는 것이 중요
    2. '저 사람은 나보다 이 분야에 대해 더 공부했구나. 나도 공부를 하면 저렇게 될 수 있구나'라는 마인드를 갖는 것이 중요함
    3. 남과 비교할 시 위축되고 자신감 하락 문제
        1. 작은 성공을 반복하는 것으로 극복하자

## ⭐ Water-Fall vs Agile

21세기는 짧은 사이클을 통해 돌면서 빠르게 구현 후 피드백

1. 빠르게 요구조건을 파악할 것
2. 피드백 후 반영한 할 것

## ⭐ 데이터 엔지니어의 가치

데이터 조직은 부가가치를 만드는 팀이다.

예를 들어, 다음과 같은 부가가치를 창출함으로써 성과를 증명한다.

1. 지표 정의 후 개선
    1. **⭕ 어떤 지표를 정의하고 개선해나갈 것인가?**
2. 의사결정과정에 기여
3. ML/AI를 활용한 Operation 성능 향상

## ⭐ 데이터 팀 구성원

1. Data Scientist
2. Data Analysis
3. Data Engineer
    1. Data Warehouse (vs Data Lake)
    2. 성능 비교
        1. BigQuery > Snowflake > Redshift
        2. A/B Test
        3. Data Tools

## ⭐ 데이터 팀 구조

- 회사 데이터 팀이 어느 그룹에 속하는 지 파악할 것
1. Centralized
2. Uncentrialized
3. Hybrid

→ Centralized 구조가 데이터를 효율적으로 관리할 수 있으나, 마케팅, 세일즈팀에서 데이터를 사용하기 불편할 수 있음

→ Uncentralized와 Centralized를 번갈아 바뀌는 형태이다. Hybrid 형태가 이상적

## ⭐ **일의 성공과 실패 측정**

**일의 성공과 실패를 어떻게 측정할 것이냐?**

**→ 성공을 입증할 수 있는 지표를 찾아야 함**

**→ 회사에 직접적으로 영향을 끼칠 수 있어야 함**

→ 그렇지 않으면 팀의 존재 가치에 대한 의문 발생

→ A/B Test를 통해 어떻게 도움이 될 수 있는가?

### 🔹  예시

- **Rule기반을 ML기반으로 전환**

마케터 본업은 퍼포먼스가 좋은 채널을 찾는 것

**→ 객관적으로 비교할 수 있는 시스템을 미리 만드는 것이 중요**

**→ A/B Test 프레임워크를 먼저 만들고, 미리 보여줌**

**→ 그리고 나서 ML과 Rule based를 비교함으로써 증명해야함**

### 🔹 Metrics First

1. 성과 지표를 만드는 것이 중요함

2. 데이터 인프라 역시 지표가 필요함

- 데이터 수집 중 fail한 Percent가 어떻게 되는가?
- 마케터들이 일을 원활히 할 수 있도록 지원하는 것
- 마케터들의 Mood를 관리하는 것도 중요함
- 오늘 지표가 마케터들을 위한 대쉬보드에 잘 나가는가?

3. 최종 A/B Test로 검증

아직 첫 주차이지만 미리 예약한 보람이 있을 정도로 유익한 강의였습니다. 매주 퀴즈와 과제도 있다고 하니 개인 프로젝트와 병행해서 준비해보려고 합니다. 추천 받은 도서 '빅데이터를 지탱하는 기술'를 읽고 있는 중인데 강의를 이해하는 데 큰 도움이 되고 있습니다. :)

## QnA

**궁금한 점, 조사할 점**

1. Spark, Kafka, Airflow 등 기술들의 차이는?
- 빅데이터를 지탱하는 기술이라는 책을 통해 데이터 엔지니어링의 큰 그림을 파악할 수 있었다.
- Spark는 데이터를 처리하기 위한 프레임 워크이다.
- Kafka는 실시간 데이터 처리를 효율적으로 하기 위한 메시지 큐 프레임워크이다.
- Airflow는 데이터 파이프라인 자동화 및 워크플로 작성을 위한 프레임워크이다.
